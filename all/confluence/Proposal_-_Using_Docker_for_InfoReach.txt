title: Proposal - Using Docker for InfoReach
body: ## Docker

Docker is a tool which is used to automate the deployment of applications in
lightweight containers so that applications can work efficiently in different
environments..  
  

## Why using Docker

Running applications in containers instead of virtual machines is gaining
momentum in the IT world. The technology is considered to be one of the
fastest growing in recent the history of the software industry. At its heart
lies Docker, a platform that allows users to easily pack, distribute and
manage applications within containers. In other words, It is an open-source
project that automates the deployment of applications inside software
containers.

Docker really makes it easier to create, deploy, and run applications by using
containers. And containers allow a developer to package up an application with
all of the parts it needs, such as libraries and other dependencies, and ship
it all out as one package. By doing so, the developer can be assured that the
application will run on any other Linux machine regardless of any customized
settings that machine might have that could differ from the machine used for
writing and testing the code.  
  

## Benefits of using docker

  
  

#### 1\. Return on investment & cost savings

The first advantage of using docker is the ROI. The biggest driver of most
management decisions when selecting a new product is the return on investment.
In this sense, Docker can help facilitate this type of savings by dramatically
reducing infrastructure resources. The nature of Docker is that fewer
resources are necessary to run the same application.  
  

#### 2\. Standardization & productivity

Docker containers ensure consistency across multiple development, release
cycles and standardising your environment. One of the biggest advantages to a
Docker-based architecture is actually standardization. Docker provides
repeatable development, build, test, and production environments.
Standardizing service infrastructure across the entire pipeline allows every
team member to work on a production parity environment. By doing this,
engineers are more equipped to efficiently analyze and fix bugs within the
application. This reduces the amount of time wasted on defects and increases
the amount of time available for feature development.  
Docker containers allow you to commit changes to your Docker images and
version control them. For example if you perform a component upgrade that
breaks your whole environment, it is very easy to rollback to a previous
version of your Docker image. This whole process can be tested in a few
minutes. Docker is fast, allowing you to quickly make replications and achieve
redundancy. Also, launching Docker images is as fast as running a machine
process.  
  

#### 3\. CI efficiency

Docker enables you to build a container image and use that same image across
every step of the deployment process. A huge benefit of this is the ability to
separate non-dependent steps and run them in parallel. The length of time it
takes from build to production can be sped up notably.  
  

#### 4\. Compatibility & maintainability

Eliminate the "it works on my machine" problem once and for all. One of the
benefits that the entire team will appreciate is parity. Parity, in terms of
Docker, means that your images run the same no matter which server or whose
laptop they are running on. For your developers, this means less time spent
setting up environments, debugging environment-specific issues, and a more
portable and easy-to-set-up codebase. Parity also means your production
infrastructure will be more reliable and easier to maintain.  
  

#### 5\. Simplicity & faster configurations

One of the key benefits of Docker is the way it simplifies matters. Users can
take their own configuration, put it into code and deploy it without any
problems. As Docker can be used in a wide variety of environments, the
requirements of the infrastructure are no longer linked with the environment
of the application.  
  

#### 6\. Rapid Deployment

Docker manages to reduce deployment to seconds. This is due to the fact that
it creates a container for every process and does not boot an OS. Data can be
created and destroyed without worry that the cost to bring it up again would
be higher than affordable.  
  

#### 7\. Continuous Deployment & Testing

Docker ensures consistent environments from development to production. Docker
containers are configured to maintain all configurations and dependencies
internally. So, you can use the same container from development to production
making sure there are no discrepancies or manual intervention. If you need to
perform an upgrade during a product's release cycle, you can easily make the
necessary changes to Docker containers, test them, and implement the same
changes to your existing containers. This sort of flexibility is another key
advantage of using Docker. Docker really allows you to build, test and release
images that can be deployed across multiple servers. Even if a new security
patch is available, the process remains the same. You can apply the patch,
test it and release it to production.  
  

#### 8\. Multi-Cloud Platforms

This is possibly one of Docker's greatest benefits. Over the last few years,
all major cloud computing providers, including Amazon Web Services (AWS) and
Google Compute Platform (GCP), have embraced Docker's availability and added
individual support. Docker containers can be run inside an Amazon EC2
instance, Google Compute Engine instance, Rackspace server or VirtualBox,
provided that the host OS supports Docker. If this is the case, a container
running on an Amazon EC2 instance can easily be ported between environments,
for example to VirtualBox, achieving similar consistency and functionality.
Also, Docker works very well with other providers like Microsoft Azure, and
OpenStack, and can be used with various configuration managers like Chef,
Puppet, and Ansible,etc.  
  

#### 9\. Security

And the last benefit of using docker is - security. From a security point of
view, Docker ensures that applications that are running on containers are
completely segregated and isolated from each other, granting you complete
control over traffic flow and management. No Docker container can look into
processes running inside another container. From an architectural point of
view, each container gets its own set of resources ranging from processing to
network stacks.  
  

#### And many more

  

## Docker Swarm

Docker Swarm is a group of machines that are running docker and joined into a
cluster. In other words Docker Swarm is a tool for container
orchestration(Managing and controlling multiple docker containers as a single
service).  
  

## Why need to use Docker Swarm

1\. Health check on every container  
2\. Ensure all containers are up on every system  
3\. Scaling the containers are up or down depending on the load  
4\. Adding updates/changes to all the containers


